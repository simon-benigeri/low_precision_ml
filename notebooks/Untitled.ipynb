{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from qtorch.quant import Quantizer, quantizer\n",
    "from qtorch.optim import OptimLP\n",
    "from torch.optim import SGD\n",
    "from qtorch import FloatingPoint\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use QPyTorch Quantizer just as any other nn.Modules\n",
    "from torch.nn import Module, Linear\n",
    "class LinearLP(Module):\n",
    "    \"\"\"\n",
    "    a low precision Logistic Regression model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LinearLP, self).__init__()\n",
    "        self.W = Linear(5, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.W(x)\n",
    "        out = Q(out)\n",
    "        return out\n",
    "    \n",
    "lp_model = LinearLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtorch.quant import fixed_point_quantize, block_quantize, float_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Precision: tensor([0.6386, 0.0622, 0.2246, 0.3209, 0.8434])\n",
      "Low Precision: tensor([0.6250, 0.0625, 0.2188, 0.3125, 0.8750])\n"
     ]
    }
   ],
   "source": [
    "full_precision_tensor = torch.rand(5)\n",
    "print(\"Full Precision: {}\".format(full_precision_tensor))\n",
    "low_precision_tensor = float_quantize(full_precision_tensor, exp=5, man=2, rounding=\"nearest\")\n",
    "print(\"Low Precision: {}\".format(low_precision_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest: tensor([0.6250, 0.0625, 0.2188, 0.3125, 0.8750])\n",
      "Stochastic: tensor([0.6250, 0.0547, 0.2188, 0.3125, 0.7500])\n"
     ]
    }
   ],
   "source": [
    "nearest_rounded = float_quantize(full_precision_tensor, exp=5, man=2, rounding=\"nearest\")\n",
    "stochastic_rounded = float_quantize(full_precision_tensor, exp=5, man=2, rounding=\"stochastic\")\n",
    "print(\"Nearest: {}\".format(nearest_rounded))\n",
    "print(\"Stochastic: {}\".format(stochastic_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
